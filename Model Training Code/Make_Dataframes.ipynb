{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e8add46-b264-459d-a36e-36ddffd66e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use if using colab\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "import argparse\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.stats import loguniform\n",
    "from scipy.io import loadmat\n",
    "from sklearn import metrics\n",
    "from torch.utils import data\n",
    "from IPython.display import clear_output\n",
    "# add current work directory in path\n",
    "sys.path.append(os.getcwd())\n",
    "from Data_Processing_Utils import Norm_each_sub_by_own_param,NormalizeData, train_val_test_split_df, PlotLoss, plot_confusion_matrix, \\\n",
    "    Get_Sub_Norm_params, windowing_Dataframe\n",
    "\n",
    "from DATALOADERS import dataframe_dataset_triplet, Pandas_Dataset\n",
    "\n",
    "from MODELS import MKCNN, MKCNN_grid, random_choice, train_model_triplet, pre_train_model_triplet, train_model_standard, MultiKernelConv2D_grid\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db039886-48f4-47f3-9567-428707b4238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom pandas dataset class modified to provide also the angle\n",
    "# used for multi-model testing\n",
    "class Pandas_Dataset_angle(data.Dataset):\n",
    "\n",
    "    def __init__(self, df_grouped_by_samples, return_sub=False):\n",
    "        self.grouped = df_grouped_by_samples\n",
    "        self.channels = [i for i in df_grouped_by_samples.obj.columns if 'ch' in i]\n",
    "        self.indices = list(df_grouped_by_samples.indices)\n",
    "        self.return_sub = return_sub\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.grouped)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        picked_smp = self.grouped.get_group(self.indices[index])\n",
    "        # Picking only the channels columns from a single sample\n",
    "        sample = torch.tensor(picked_smp.loc[:, self.channels].values).type(torch.float32)\n",
    "        # picking only one label for each sample\n",
    "        label = torch.tensor(picked_smp.loc[:, ['label']].head(1).values[0][0]).type(torch.int8)\n",
    "        angle = torch.tensor(picked_smp.loc[:, ['angle']].head(1).values[0][0]).type(torch.int16)\n",
    "        if self.return_sub:\n",
    "            # picking only one subject\n",
    "            sub = torch.tensor(picked_smp.loc[:, ['sub']].head(1).values[0][0]).type(torch.int8)\n",
    "            return sample, label, angle, sub\n",
    "        else:\n",
    "\n",
    "            # It's missing the part in which I Normalize the data for each subject, or for each subject and channels\n",
    "            # It's not a good idea to do that on the dataloader while producing results\n",
    "            return sample, label, angle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05de73e5-d154-4967-a601-3aa3bed603f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function used to merge the dataframes\n",
    "def make_merged_df(dfs_path: str, wnd_list: list, save = True, save_path: str = None):\n",
    "    \"\"\"\n",
    "    dfs_path: folder where the windowed dataframes are stored\n",
    "    wnd_list: list with the name of the windowed dfs to merge\n",
    "    \"\"\"\n",
    "    print(\"Merging Angles Dataframes...\")\n",
    "    #wnd_list = [x for x in sorted(os.listdir(dfs_path)) if name in x]\n",
    "    dfs = []\n",
    "    prev_df_lenghts = 0\n",
    "    i = 0\n",
    "    # loop to merge all the windowed dataframes into one, while changing the sample_index accordingly\n",
    "    for dataframe in wnd_list:\n",
    "        df = pd.read_csv(dfs_path+dataframe)\n",
    "        df['sample_index'] = df['sample_index'] + prev_df_lenghts +1*(i>0)\n",
    "        df\n",
    "        dfs.append(df)\n",
    "        prev_df_lenghts = df['sample_index'].iloc[-1]\n",
    "        i+=1\n",
    "\n",
    "    total_df = pd.concat(dfs, ignore_index = True)\n",
    "    #print(total_df.shape)\n",
    "    total_df_chs = [col for col in total_df.columns if 'Ch' in col]\n",
    "    total_df[total_df_chs] = total_df[total_df_chs].astype(np.uint16)\n",
    "    total_df['angle'] = total_df['angle'].astype(np.int16)\n",
    "\n",
    "    minAngle, maxAngle = total_df['angle'].abs().min(), total_df['angle'].abs().max()\n",
    "    print(f\"minAngle: {minAngle} maxAngle: {maxAngle}\")\n",
    "    angleRange = maxAngle - minAngle\n",
    "    interval = 5*round(angleRange * 0.125/5) #round interval to the closest multiple of 5\n",
    "    residue = angleRange-interval*8\n",
    "    intervals = [abs(minAngle+interval), abs(minAngle+interval*3), abs(maxAngle-interval*3), abs(maxAngle-interval)]\n",
    "    print(f\"Angle Intervals: {intervals}\")\n",
    "\n",
    "    angle_index = []\n",
    "    for ang in total_df['angle']:\n",
    "        ang = abs(ang)\n",
    "        if ang < intervals[0]:\n",
    "            angle_index.append(1)\n",
    "        elif ang < intervals[1]:\n",
    "            angle_index.append(2)\n",
    "        elif ang < intervals[2]:\n",
    "            angle_index.append(3)\n",
    "        elif ang < intervals[3]:\n",
    "            angle_index.append(4)\n",
    "        else:\n",
    "            angle_index.append(5)\n",
    "\n",
    "    if 'Unnamed: 0' in total_df.columns:\n",
    "        total_df.drop('Unnamed: 0', axis = 1, inplace =True)\n",
    "    total_df[\"angle_index\"] = angle_index\n",
    "    total_df[\"angle_index\"] = total_df[\"angle_index\"].astype(np.int8)\n",
    "\n",
    "    if save:\n",
    "        if not os.path.exists(save_path):\n",
    "          os.makedirs(save_path)\n",
    "        save_directory = (dfs_path if save_path == None else save_path) + 'dataframe_wnd_200_angle_merged.csv'\n",
    "        total_df.to_csv(save_directory, index = False)\n",
    "        print(\"\\nMerged angles saved at ----> \"+ save_directory+\"\\n\")\n",
    "    return total_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a3e7eee-8433-46be-bb68-458ef02ab888",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data path\n",
    "data_path = os.getcwd() + '/DATA/'\n",
    "\n",
    "subjects = [ 'Sub2']\n",
    "days = [1] #be sure that all the subject have the days you want to use\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92059b9f-e7d2-49a5-aca6-d7799bbac49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory and data creation\n",
    "# set window length and overlap for the windowing\n",
    "WND_LEN = 200\n",
    "overlap = 0.5\n",
    "n_channels = 8\n",
    "columns = [f'Ch{ch}' for ch in range(1, n_channels+1)]\n",
    "\n",
    "# True if you want to generate, merge and modify the dataframes\n",
    "# You have to do this the first time\n",
    "operate_on_df = True \n",
    "# True if you want to generate the dataframes\n",
    "make_dataframes = True\n",
    "# True if you want to merge the days 1  and 2\n",
    "merge_days = False\n",
    "# True if you want to merge the angles\n",
    "# It's advised to merge all the angles in one dataframe to save space and complexity\n",
    "# A new column 'angle_index' will be added to keep track of which angle is which\n",
    "merge_angles = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e4fb60e-eeb6-4ebd-bcee-a8d7af820c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windowing subject: 1\n",
      "Saved in -> C:\\Users\\sarto\\OneDrive\\Desktop\\Git Repo\\Model Training Code/DATA//Sub2/day1/Dataframe/  as -> dataframe_wnd_200_angle_1.csv\n",
      "Windowing subject: 1\n",
      "Saved in -> C:\\Users\\sarto\\OneDrive\\Desktop\\Git Repo\\Model Training Code/DATA//Sub2/day1/Dataframe/  as -> dataframe_wnd_200_angle_2.csv\n",
      "Windowing subject: 1\n",
      "Saved in -> C:\\Users\\sarto\\OneDrive\\Desktop\\Git Repo\\Model Training Code/DATA//Sub2/day1/Dataframe/  as -> dataframe_wnd_200_angle_3.csv\n",
      "Windowing subject: 1\n",
      "Saved in -> C:\\Users\\sarto\\OneDrive\\Desktop\\Git Repo\\Model Training Code/DATA//Sub2/day1/Dataframe/  as -> dataframe_wnd_200_angle_4.csv\n",
      "Windowing subject: 1\n",
      "Saved in -> C:\\Users\\sarto\\OneDrive\\Desktop\\Git Repo\\Model Training Code/DATA//Sub2/day1/Dataframe/  as -> dataframe_wnd_200_angle_5.csv\n",
      "['dataframe_wnd_200_angle_1.csv', 'dataframe_wnd_200_angle_2.csv', 'dataframe_wnd_200_angle_3.csv', 'dataframe_wnd_200_angle_4.csv', 'dataframe_wnd_200_angle_5.csv']\n",
      "Merging Angles Dataframes...\n",
      "minAngle: 0 maxAngle: 105\n",
      "Angle Intervals: [15, 45, 60, 90]\n",
      "\n",
      "Merged angles saved at ----> C:\\Users\\sarto\\OneDrive\\Desktop\\Git Repo\\Model Training Code/DATA//Sub2/day1/Dataframe/dataframe_wnd_200_angle_merged.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataframe creation and manipulation\n",
    "for subj in subjects:\n",
    "    for day in days:\n",
    "        current_path = data_path+f'{subj}/day{day}/mat/'\n",
    "        save_path = data_path+f'/{subj}/day{day}/Dataframe/'\n",
    "        if operate_on_df:\n",
    "            if make_dataframes:\n",
    "                EMG_data = os.listdir(current_path)\n",
    "                for name in EMG_data:\n",
    "                    angle = re.search(r'%s(\\d+)' % 'angle_', name).group(1)\n",
    "                    mat = loadmat(current_path + name)\n",
    "                    df = pd.DataFrame(data=mat['emg'], columns=columns, dtype=np.uint32)\n",
    "                    df['Exe_Num'] = mat['relabel_stimulus'].astype(np.uint8)\n",
    "                    df['Rep_Num'] = mat['relabel_repetition'].astype(np.uint8)\n",
    "                    df['Sub'] = np.full(shape=len(df), fill_value=1).astype(np.uint8)\n",
    "                    df['Angle'] = mat['angle'].astype(np.int16)\n",
    "                    df = df.loc[df['Exe_Num'] != 0]     # Deleting rest position\n",
    "                    df = df.loc[df['Rep_Num'] != 0]     # Deleting other, if remaining (shouldn't but some in day1 angle 4) resting position (?)\n",
    "                    df['Exe_Num'] = df['Exe_Num'] - 1    # Starting label from 0\n",
    "                    #df.to_csv(database + f'dataframe_ang_{angle}_no_rest.csv', columns=df.columns)\n",
    "                    windowing_Dataframe(df, WND_LEN, overlap_perc=overlap, NinaPro_Database_Num=None, drop_last=False, keep_angle = True,\n",
    "                                        path_to_save=save_path, filename=f'dataframe_wnd_{WND_LEN}_angle_{angle}.csv')\n",
    "        \n",
    "            # % Merging day1 and day2, saving day-type in 'sub' column because, being all the signals from same subject (Giulio Sartorato),\n",
    "            # there is no need to keep sub column. Moreover, having some functions working for domain adaptation between subject,\n",
    "            # using column subject to perform INTER-DAY analysis will become easier.\n",
    "            if merge_days:\n",
    "                print(f'Merging: -> dataframe_wnd_{WND_LEN}_angle_merged  of day1 & day2')\n",
    "                path = data_path + f'{subj}/day1/Dataframe/'\n",
    "                os.chdir(path)\n",
    "                df1 = pd.read_csv(path + f'dataframe_wnd_{WND_LEN}_angle_merged.csv')\n",
    "                path = data_paht + f'{subj}/day2/Dataframe/'\n",
    "                os.chdir(path)\n",
    "                df2 = pd.read_csv(path + f'dataframe_wnd_{WND_LEN}_angle_merged.csv')\n",
    "        \n",
    "                df2['sub'] = df2['sub'] + 1   # It will represent day2\n",
    "                df2['sample_index'] = df2['sample_index'] + max(df1.sample_index) + 1   # Correcting sample_index to be unique for each window\n",
    "        \n",
    "                df = pd.concat([df1, df2])\n",
    "                merge_save_dir = data_path + f'{subj}/merged_day1_2/'\n",
    "                if not os.path.exists(merge_save_dir):\n",
    "                    os.makedirs(merge_save_dir)\n",
    "                df.to_csv(merge_save_dir + f'Dataframe/df_merged_wnd_{WND_LEN}_ang_merged.csv', columns=df.columns, index=False)\n",
    "        \n",
    "            if merge_angles:\n",
    "                s_string = \"_angle\"\n",
    "                df_list = [x for x in os.listdir(save_path) if s_string in x]\n",
    "                print(df_list)\n",
    "                make_merged_df(dfs_path=save_path,wnd_list=  df_list, save = True, save_path=save_path)\n",
    "                for df in df_list:\n",
    "                    os.remove(save_path+df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639ce5aa-40dd-4cc5-8155-7746da62966a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
